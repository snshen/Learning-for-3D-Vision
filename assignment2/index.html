<html><head><style>body {
   color: black;
}
</style></head><body><h1 id="16-825-assignment-2-single-view-to-3d">16-825 Assignment 2: Single View to 3D</h1>
<p>number or late days used:
<img src="./data/three.png"  width="5%"></p>
<h2 id="1-exploring-loss-functions">1. Exploring loss functions</h2>
<h3 id="1-1-fitting-a-voxel-grid-5-points-">1.1. Fitting a voxel grid (5 points)</h3>
<p>Visualize the optimized voxel grid along-side the ground truth voxel grid using the tools learnt in previous section.</p>
<table>
<thead>
<tr>
<th style="text-align:center">Ground Truth</th>
<th style="text-align:center">Optomized</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="./data/fit/target_vox.gif" alt="First Image"></td>
<td style="text-align:center"><img src="./data/fit/source_vox.gif" alt="Second Image"></td>
</tr>
</tbody>
</table>
<h3 id="1-2-fitting-a-point-cloud-10-points-">1.2 Fitting a point cloud (10 points)</h3>
<p>Visualize the optimized point cloud along-side the ground truth point cloud using the tools learnt in previous section.</p>
<table>
<thead>
<tr>
<th style="text-align:center">Ground Truth</th>
<th style="text-align:center">Optomized</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="./data/fit/target_cloud.gif" alt="First Image"></td>
<td style="text-align:center"><img src="./data/fit/source_cloud.gif" alt="Second Image"></td>
</tr>
</tbody>
</table>
<h3 id="1-3-fitting-a-mesh-5-points-">1.3 Fitting a mesh (5 points)</h3>
<p>Visualize the optimized mesh along-side the ground truth mesh using the tools learnt in previous section.</p>
<table>
<thead>
<tr>
<th style="text-align:center">Ground Truth</th>
<th style="text-align:center">Optomized</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="./data/fit/target_mesh.gif" alt="First Image"></td>
<td style="text-align:center"><img src="./data/fit/source_mesh.gif" alt="Second Image"></td>
</tr>
</tbody>
</table>
<h2 id="2-reconstructing-3d-from-single-view">2. Reconstructing 3D from single view</h2>
<h3 id="2-1-image-to-voxel-grid-15-points-">2.1. Image to voxel grid (15 points)</h3>
<p>Visuals of any three examples in the test set. For each example show the input RGB, render of the predicted 3D voxel grid and a render of the ground truth mesh.</p>
<table>
<thead>
<tr>
<th style="text-align:center">Input RGB</th>
<th style="text-align:center">Ground Truth Mesh</th>
<th style="text-align:center">Ground Truth Voxel</th>
<th style="text-align:center">Predicted Voxel</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="./data/gt_image_1.png" alt="First Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh_t0.gif" alt="Second Image"></td>
<td style="text-align:center"><img src="./data/vox/model_vox_t0.gif" alt="third Image"></td>
<td style="text-align:center"><img src="./data/vox/model_vox0.gif" alt="Fourth Image"></td>
</tr>
<tr>
<td style="text-align:center"><img src="./data/gt_image_2.png" alt="First Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh_t1.gif" alt="Second Image"></td>
<td style="text-align:center"><img src="./data/vox/model_vox_t1.gif" alt="third Image"></td>
<td style="text-align:center"><img src="./data/vox/model_vox1.gif" alt="Fourth Image"></td>
</tr>
<tr>
<td style="text-align:center"><img src="./data/gt_image_5.png" alt="First Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh_t2.gif" alt="Second Image"></td>
<td style="text-align:center"><img src="./data/vox/model_vox_t2.gif" alt="third Image"></td>
<td style="text-align:center"><img src="./data/vox/model_vox2.gif" alt="Fourth Image"></td>
</tr>
</tbody>
</table>
<p>The Voxel Model I had implemented was based on Pixel2Mesh, with the two major difference being the use of Leaky ReLU instead of ELU and a shorter run time/different scheduler milestones (75 epochs with milestone at 50 instead of 350 epochs with milestones and refinement at [150, 250]). Also note that instead of saving the latest model, I saved the model which scored the highest average F1 value (evaluated once every epoch); this technique holds true for the subsequent models as well.</p>
<!-- The f1 scores of visualized models are: 100.000, 77.271, and 97.291 -->
<h3 id="2-2-image-to-point-cloud-15-points-">2.2 Image to point cloud (15 points)</h3>
<p>Visuals of any three examples in the test set. For each example show the input RGB, render of the predicted 3D point cloud and a render of the ground truth mesh.</p>
<table>
<thead>
<tr>
<th style="text-align:center">Input RGB</th>
<th style="text-align:center">Ground Truth Mesh</th>
<th style="text-align:center">Ground Truth Cloud</th>
<th style="text-align:center">Predicted Cloud</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="./data/gt_image_1.png" alt="First Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh_t0.gif" alt="Second Image"></td>
<td style="text-align:center"><img src="./data/point/model_cloud_t0.gif" alt="third Image"></td>
<td style="text-align:center"><img src="./data/point/model_cloud0.gif" alt="Fourth Image"></td>
</tr>
<tr>
<td style="text-align:center"><img src="./data/gt_image_2.png" alt="First Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh_t1.gif" alt="Second Image"></td>
<td style="text-align:center"><img src="./data/point/model_cloud_t1.gif" alt="third Image"></td>
<td style="text-align:center"><img src="./data/point/model_cloud1.gif" alt="Fourth Image"></td>
</tr>
<tr>
<td style="text-align:center"><img src="./data/gt_image_5.png" alt="First Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh_t2.gif" alt="Second Image"></td>
<td style="text-align:center"><img src="./data/point/model_cloud_t2.gif" alt="third Image"></td>
<td style="text-align:center"><img src="./data/point/model_cloud2.gif" alt="Fourth Image"></td>
</tr>
</tbody>
</table>
<p>The cloud model I implemented was a simple 2 FCL model which was run for 40 epochs (with last saved model at epoch 31). I had tried expanding the model to be larger, however I found that this simple model outperformed all deeper, wider, and more complex (with convolution) models. </p>
<!-- The f1 scores of visualized models are: 99.850, 99.710, and 98.959 -->
<h3 id="2-3-image-to-mesh-15-points-">2.3 Image to mesh (15 points)</h3>
<p>Visuals of any three examples in the test set. For each example show the input RGB, render of the predicted mesh and a render of the ground truth mesh.</p>
<table>
<thead>
<tr>
<th style="text-align:center">Input RGB</th>
<th style="text-align:center">Ground Truth Mesh</th>
<th style="text-align:center">Predicted Mesh</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="./data/gt_image_1.png" alt="First Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh_t0.gif" alt="Second Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh0.gif" alt="third Image"></td>
</tr>
<tr>
<td style="text-align:center"><img src="./data/gt_image_2.png" alt="First Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh_t1.gif" alt="Second Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh1.gif" alt="third Image"></td>
</tr>
<tr>
<td style="text-align:center"><img src="./data/gt_image_5.png" alt="First Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh_t2.gif" alt="Second Image"></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh2.gif" alt="third Image"></td>
</tr>
</tbody>
</table>
<p>The mesh model I implemented was a simple FCL model which was run for 25 epochs. Similarly to the point cloud model, I had tried expanding the model to be larger and, again, found that this simple model outperformed all deeper, wider, and more complex (with convolution) models.</p>
<h3 id="2-4-quantitative-comparisions-10-points-">2.4 Quantitative comparisions(10 points)</h3>
<p>Average test F1 score at 0.05 threshold for voxelgrid, pointcloud and the mesh network.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th style="text-align:center">Voxel</th>
<th style="text-align:center">Point Cloud</th>
<th style="text-align:center">Mesh</th>
</tr>
</thead>
<tbody>
<tr>
<td>Avg F1@0.05</td>
<td style="text-align:center">90.890</td>
<td style="text-align:center">96.155</td>
<td style="text-align:center">93.394</td>
</tr>
</tbody>
</table>
<p>Something to note before discussion is that all the models I had implemented were run until loss seemed to stop decreasing, however the runtime and complexity of the Voxel model was significantly higher than the other two as mentioned in the previouse sections. Keeping this in mind, here is an intutive explaination justifying the comparision between models:</p>
<ol>
<li>The point cloud model performed the best. Intuitively and in practice, point clouds are the easiest to optomize. Since points in a cloud are not bound by connectivity, they are not affected by the need to define faces besed on vertex connections (such as with mesh). Because of this factor, misplacement of a single point in a pointcloud does not affect the rest of the model as much as a vertex can affect a mesh model, therefore allowing the model to converge faster and for the prediction model to be simpler.</li>
<li>While the mesh model technically performed the better than the voxel model, visually it is the least convincing. Intuitively, the reasonable placement of the vertices makes sense for the same reasons as the point cloud model. On the other hand, the inability for the model to predict face orientation well also makes sense due to the now sampling value being used (default of n_points=5000) when calculating loss. Since the number of faces on the ground truth and predicted models are higher than 5000, it makes sense that the model&#39;s loss values are not as informative as desired. Another disadvantage that the model faces is the constraint of the spherical topology. This factor makes it impossible for the mesh to accurately represent chairs that require more complex topologies (such as designs that place holes in the backrest of the chair or armrests that form a loop).</li>
<li>The voxel model performed worse than point cloud and mesh. This is somewhat surprising since it benefitted from a well designed architecture that utilizes 3D convolutions which allowed it to gain more spatial reasoning about the discretized space (in this case designated to be 32x32x32). Furthermore, this model in particular benefitted from longer runtime than the other models which seems to have. However, it looks better than the mesh models even though it had a worse performance score. This discrepency may be due to the fact that the resolution of the voxel discretization is rather coarse, therefore the model has a hard time representing details, as seen in section 2.6; it can only represent volume by a fixed voxel size regardless of how small the occuying piece is. Therefore, even though the model is reasonably tuned and looks reasonable, the final model scores comparitively poorly on F1 likely due to shortcomings of the voxel representation.</li>
</ol>
<p>The generated F1 score curves are included for reference:
| Voxel | Point Cloud | Mesh |
|:-:|:-:|:-:|
|<img src="./data/eval_vox.png" alt="First Image">|<img src="./data/eval_point.png" alt="Second Image">|<img src="./data/eval_mesh.png" alt="third Image">|</p>
<h3 id="2-5-analyse-effects-of-hyperparms-variations-10-points-">2.5 Analyse effects of hyperparms variations (10 points)</h3>
<p>Due to the fact that the surfaces of the mesh model seemed so disjointed, I chose to analyze the effect of w_smooth and see if I could obtain a better result. In order to do so, I trained 4 models (25 epochs each) with the following w_smooth values: 0.01, 1.0, 2.0, 3.0, 4.0, and 5.0. Throughout this process all other parameters remailed constant and w_chamfer was set to 1.0. Note that I did have a reduce on plateau scheduler in place that may have caused some discrepancies in training process. The outcomes of my models were as follows:</p>
<table>
<thead>
<tr>
<th>w_smooth</th>
<th style="text-align:center">0.01</th>
<th style="text-align:center">1.0</th>
<th style="text-align:center">2.0</th>
<th style="text-align:center">3.0</th>
<th style="text-align:center">4.0</th>
<th style="text-align:center">5.0</th>
</tr>
</thead>
<tbody>
<tr>
<td>Example 0</td>
<td style="text-align:center"><img src="./data/param/mesh0_0.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh0_1.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh0_2.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh0_3.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh0_4.gif" alt=""></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh0.gif" alt=""></td>
</tr>
<tr>
<td>Example 1</td>
<td style="text-align:center"><img src="./data/param/mesh1_0.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh1_1.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh1_2.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh1_3.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh1_4.gif" alt=""></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh1.gif" alt=""></td>
</tr>
<tr>
<td>Example 2</td>
<td style="text-align:center"><img src="./data/param/mesh2_0.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh2_1.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh2_2.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh2_3.gif" alt=""></td>
<td style="text-align:center"><img src="./data/param/mesh2_4.gif" alt=""></td>
<td style="text-align:center"><img src="./data/mesh/model_mesh2.gif" alt=""></td>
</tr>
<tr>
<td>f1@0.05</td>
<td style="text-align:center">91.390</td>
<td style="text-align:center">90.755</td>
<td style="text-align:center">93.027</td>
<td style="text-align:center">93.036</td>
<td style="text-align:center">93.394</td>
<td style="text-align:center">93.521</td>
</tr>
</tbody>
</table>
<p>As seen, as the w_smooth value increased, there seemed to be a general trend of visual improvement and increase in F1 score. However, the improvement was definitely non-linear Note that, my aws instance had some internal issues while training my 0.01 and 1.0 model so I the training may have been cut off earlier than expected.</p>
<h3 id="2-6-interpret-your-model-15-points-">2.6 Interpret your model (15 points)</h3>
<p>Simply seeing final predictions and numerical evaluations is not always insightful. Can you create some visualizations that help highlight what your learned model does? Be creative and think of what visualizations would help you gain insights. There is no `right&#39; answer - although reading some papers to get inspiration might give you ideas.</p>
<p>As I watched my models train, I noticed that the models seemed to first learn to predict a generic &quot;seat&quot; shaped blob before further training allowed them more accurately represent the individual inputs. However, I suspect that the models still have a &quot;default&quot; behavior in scenarios where the input is unusual or difficult to interperate. To help visualize this behavior, I have included 3 edge cases in which this behavior emerges.</p>
<p>First, detailed designs. These are cases in which the seats have relatively intricate designs or unusual decorations which is seems to confuse the model as they have no consistent representation within the dataset, these instances usually result in a very generic chair shaped output that ignore the details.</p>
<table>
<thead>
<tr>
<th>label</th>
<th style="text-align:center">example 1</th>
<th style="text-align:center">example 2</th>
<th style="text-align:center">example 3</th>
</tr>
</thead>
<tbody>
<tr>
<td>target</td>
<td style="text-align:center"><img src="./data/edge/chair_0_t.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/chair_1_t.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/chair_2_t.gif" alt=""></td>
</tr>
<tr>
<td>prediction</td>
<td style="text-align:center"><img src="./data/edge/chair_0.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/chair_1.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/chair_2.gif" alt=""></td>
</tr>
</tbody>
</table>
<p>Second, unique legs. These are cases in which the seats have uncommon leg designs. While the model is very good at predicting, and defaults to having, either a generic four legged chairs or some sort of single support seat, it struggles to identify orther characteristics like rollers, thin leg, or unique shaped supports. Note that this effect is especially prominent with thin legs and could be at least partially attributed to the fact that, because they take up so little space, they are unlikely to be well sampled in the training process and thus difficult for the model to learn.</p>
<table>
<thead>
<tr>
<th>label</th>
<th style="text-align:center">example 1</th>
<th style="text-align:center">example 2</th>
<th style="text-align:center">example 3</th>
</tr>
</thead>
<tbody>
<tr>
<td>target</td>
<td style="text-align:center"><img src="./data/edge/leg_0_t.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/leg_2_t.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/leg_3_t.gif" alt=""></td>
</tr>
<tr>
<td>prediction</td>
<td style="text-align:center"><img src="./data/edge/leg_0.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/leg_2.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/leg_3.gif" alt=""></td>
</tr>
</tbody>
</table>
<p>Third, oddly shapped seats. These are cases in which the seats does not follow the general form factor of the rest of the examples. In these cases, the &quot;defaulting&quot; behavior is especially prominent. Whenever, the model encounters these unusual seats it seems to default to a few generic features of chairs such as arm rests, flat (and mostly square) backs, and some sort of perpendicular support. Thus, the resulting prediction looks somewhat like a chair, just not the chair being targetted.</p>
<table>
<thead>
<tr>
<th>label</th>
<th style="text-align:center">example 1</th>
<th style="text-align:center">example 2</th>
<th style="text-align:center">example 3</th>
</tr>
</thead>
<tbody>
<tr>
<td>target</td>
<td style="text-align:center"><img src="./data/edge/wierd_0_t.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/wierd_2_t.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/wierd_3_t.gif" alt=""></td>
</tr>
<tr>
<td>prediction</td>
<td style="text-align:center"><img src="./data/edge/wierd_0.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/wierd_2.gif" alt=""></td>
<td style="text-align:center"><img src="./data/edge/wierd_3.gif" alt=""></td>
</tr>
</tbody>
</table>
<h2 id="3-extra-credit-exploring-some-recent-architectures-">3. (Extra Credit) Exploring some recent architectures.</h2>
</body></html>